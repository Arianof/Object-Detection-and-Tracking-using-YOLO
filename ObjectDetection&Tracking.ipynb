{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XFIM_BBMh_7"
      },
      "source": [
        "# 1. Requierments and Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlhhYGy7YkV0",
        "outputId": "fd3217ba-1b36-4d49-b675-a49df17513a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.86-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.6-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.86-py3-none-any.whl (872 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.0/872.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.6-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.2.86 ultralytics-thop-2.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHt5TFyfcbyM",
        "outputId": "12f82360-a129-4a2c-e142-86529215b1ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Collecting lap\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Building wheels for collected packages: lap\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp310-cp310-linux_x86_64.whl size=1628948 sha256=75e260836b451dbe24bc6dcf2b6ae786d0086507ec441e913e444bf618f83e08\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/42/2e/9dfe19270eea279d79e84767ff0d7b8082c3bf776cad00e83d\n",
            "Successfully built lap\n",
            "Installing collected packages: lap\n",
            "Successfully installed lap-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn lap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62ApkCkk7ePL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFGPU3V0MrOK"
      },
      "source": [
        "# 2. Preprocesses and setting Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWXWVLdfbL04"
      },
      "source": [
        "## 2.1 Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUE3W3A7bLQr"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "  BotSort_Yaml = \"\"\"\n",
        "tracker_type: bytetrack # tracker type, ['botsort', 'bytetrack']\n",
        "track_high_thresh: 0.6 # threshold for the first association\n",
        "track_low_thresh: 0.3 # threshold for the second association\n",
        "new_track_thresh: 0.85 # threshold for init new track if the detection does not match any tracks\n",
        "track_buffer: 100 # buffer to calculate the time when to remove tracks\n",
        "match_thresh: 0.6 # threshold for matching tracks\n",
        "fuse_score: True # Whether to fuse confidence scores with the iou distances before matching\n",
        "min_box_area: 10  # threshold for min box areas(for tracker evaluation, not used for now)\n",
        "# BoT-SORT settings\n",
        "gmc_method: sparseOptFlow # method of global motion compensation\n",
        "# ReID model related thresh (not supported yet)\n",
        "proximity_thresh: 0.6\n",
        "appearance_thresh: 0.6\n",
        "with_reid: True\n",
        "\"\"\"\n",
        "  Bytetrack_Yaml = \"\"\"\n",
        "  tracker_type: bytetrack # tracker type, ['botsort', 'bytetrack']\n",
        "  track_high_thresh: 0.35 # threshold for the first association\n",
        "  track_low_thresh: 0.025 # threshold for the second association\n",
        "  new_track_thresh: 0.8 # threshold for init new track if the detection does not match any tracks\n",
        "  track_buffer: 300 # buffer to calculate the time when to remove tracks\n",
        "  match_thresh: 0.8 # threshold for matching tracks\n",
        "  fuse_score: True # Whether to fuse confidence scores with the iou distances before matching\n",
        "  min_box_area: 1  # threshold for min box areas(for tracker evaluation, not used for now)\n",
        "  \"\"\"\n",
        "\n",
        "  output_path = '/content/output_video.mp4'\n",
        "\n",
        "  tracker=\"botsort.yaml\"\n",
        "\n",
        "  imgsz=1280\n",
        "\n",
        "  conf=0.2\n",
        "\n",
        "  iou=0.7\n",
        "\n",
        "  font_scale = 0.9\n",
        "\n",
        "  thickness = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5lSapSmM0yC"
      },
      "source": [
        "## 2.2 Setting BotSort yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaHsqE4k0ful"
      },
      "outputs": [],
      "source": [
        "# default values of botsort\n",
        "#tracker_type: bytetrack # tracker type, ['botsort', 'bytetrack']\n",
        "#track_high_thresh: 0.5 # threshold for the first association\n",
        "#track_low_thresh: 0.1 # threshold for the second association\n",
        "#new_track_thresh: 0.6 # threshold for init new track if the detection does not match any tracks\n",
        "#track_buffer: 30 # buffer to calculate the time when to remove tracks\n",
        "#match_thresh: 0.8 # threshold for matching tracks\n",
        "#fuse_score: True # Whether to fuse confidence scores with the iou distances before matching\n",
        "#min_box_area: 10  # threshold for min box areas(for tracker evaluation, not used for now)\n",
        "# BoT-SORT settings\n",
        "#gmc_method: sparseOptFlow # method of global motion compensation\n",
        "# ReID model related thresh (not supported yet)\n",
        "#proximity_thresh: 0.5\n",
        "#appearance_thresh: 0.25\n",
        "#with_reid: False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXt_gNFnLvoM"
      },
      "outputs": [],
      "source": [
        "def set_BotSort_yaml():\n",
        "  # Write to YAML file\n",
        "  with open(\"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/trackers/botsort.yaml\", \"w\") as file:\n",
        "      file.write(Config.BotSort_Yaml)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLIy1U5d4y5t"
      },
      "outputs": [],
      "source": [
        "def view_BotSort_yaml():\n",
        "  # View the contents of the botsort.yaml file\n",
        "  !cat /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/trackers/botsort.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTWZdsPjM9RN"
      },
      "source": [
        "## 2.3 Setting ByteTrack yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USYBWYXTJhtw"
      },
      "outputs": [],
      "source": [
        "# default values of bytetrack\n",
        "#tracker_type: bytetrack # tracker type, ['botsort', 'bytetrack']\n",
        "#track_high_thresh: 0.5 # threshold for the first association\n",
        "#track_low_thresh: 0.1 # threshold for the second association\n",
        "#new_track_thresh: 0.6 # threshold for init new track if the detection does not match any tracks\n",
        "#track_buffer: 30 # buffer to calculate the time when to remove tracks\n",
        "#match_thresh: 0.8 # threshold for matching tracks\n",
        "#fuse_score: True # Whether to fuse confidence scores with the iou distances before matching\n",
        "#min_box_area: 10  # threshold for min box areas(for tracker evaluation, not used for now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOu0neln0ewI"
      },
      "outputs": [],
      "source": [
        "def set_ByteTrack_yaml():\n",
        "  # Write to YAML file\n",
        "  with open(\"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/trackers/bytetrack.yaml\", \"w\") as file:\n",
        "      file.write(Config.Bytetrack_Yaml)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83OI3t6e5vMT"
      },
      "outputs": [],
      "source": [
        "def view_ByteTrack_yaml():\n",
        "  # View the contents of the bytetrack.yaml file\n",
        "  !cat /usr/local/lib/python3.10/dist-packages/ultralytics/cfg/trackers/bytetrack.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEBxlTZuNX97"
      },
      "source": [
        "# 3. Image Enhancements Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlO7UG-9NgH6"
      },
      "outputs": [],
      "source": [
        "def blur(frame):\n",
        "  blurred_frame = cv2.blur(frame, (5, 5))\n",
        "  return blurred_frame\n",
        "\n",
        "def gaussian_blur(frame):\n",
        "  blurred_frame = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "  return blurred_frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0h0NznwNA_T"
      },
      "source": [
        "# 4. Object detection and Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1dbE2sldkkJ"
      },
      "outputs": [],
      "source": [
        "def load_test_videos():\n",
        "  # Input video path\n",
        "  video_path_vally = \"./vally_test2.mp4\"\n",
        "  video_path_traffic = \"./test.MOV\"\n",
        "  video_path_dogs = \"./person&dogs.mp4\"\n",
        "\n",
        "  cap = cv2.VideoCapture(video_path_dogs)\n",
        "\n",
        "  # Check if video capture initialized successfully\n",
        "  if not cap.isOpened():\n",
        "      print(\"Error: Could not open video.\")\n",
        "      exit()\n",
        "\n",
        "  return cap\n",
        "\n",
        "def make_output_video(cap):\n",
        "\n",
        "  # Get video properties\n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  frame_count = 0\n",
        "\n",
        "  # Output video path\n",
        "  output_video_path = Config.output_path\n",
        "\n",
        "  # Define the codec and create VideoWriter object to save processed frames as a video\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "  out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "  return output_video_path, out\n",
        "\n",
        "def load_model():\n",
        "  # Load the YOLO model\n",
        "  model = YOLO(\"yolov8x.pt\")\n",
        "  return model\n",
        "\n",
        "def draw_customized_boxes(result, frame):\n",
        "   # Get the boxes, class names, and identities from the results\n",
        "        for r in result[0].boxes:\n",
        "            box = r.xyxy[0]  # Extract bounding box coordinates\n",
        "            label=\"\"\n",
        "            #conf = r.conf[0]  # Extract confidence score\n",
        "            #cls = int(r.cls[0])  # Extract class ID\n",
        "\n",
        "            if r.id is not None:  # Check if the ID is available\n",
        "                obj_id = int(r.id[0])  # Get object ID\n",
        "                label = f\"id:{obj_id}\"  # Combine label and ID\n",
        "                #label = f\"{model.names[cls]} {conf:.2f} id:{obj_id}\"  # Combine label and ID\n",
        "\n",
        "            # Draw the bounding box without confidence score\n",
        "            color = (255, 0, 0)  # Blue color for bounding boxes\n",
        "            cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, 2)\n",
        "\n",
        "            # Get text size to create a background rectangle\n",
        "            font_scale = 0.9\n",
        "            thickness = 2\n",
        "            text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]\n",
        "            text_x, text_y = int(box[0]), int(box[1]) - 10\n",
        "\n",
        "            # Define the coordinates for the background rectangle\n",
        "            background_tl = (text_x, text_y - text_size[1] - 5)  # Top-left corner\n",
        "            background_br = (text_x + text_size[0] + 5, text_y + 5)  # Bottom-right corner\n",
        "\n",
        "            # Draw the blue background rectangle\n",
        "            cv2.rectangle(frame, background_tl, background_br, (255, 0, 0), -1)  # Blue background\n",
        "\n",
        "            # Draw the label text on top of the background rectangle\n",
        "            cv2.putText(frame, label, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "def detect_and_track_objects(model, cap, out):\n",
        "  try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Preprocess frames if needed\n",
        "        blurred_frame = blur(frame)\n",
        "\n",
        "        # Apply YOLO tracking\n",
        "        result = model.track(blurred_frame, persist=True, tracker=\"botsort.yaml\", imgsz=1280, conf=0.2, iou=0.7)\n",
        "\n",
        "        draw_customized_boxes(result, frame)\n",
        "\n",
        "        #cv2_imshow(frame)\n",
        "\n",
        "        # Write the processed frame to the output video file\n",
        "        out.write(frame)\n",
        "\n",
        "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "      print(\"Processing interrupted by user.\")\n",
        "  finally:\n",
        "      # Release resources properly even if the processing is interrupted\n",
        "      cap.release()\n",
        "      out.release()\n",
        "      cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "def download_output_video(output_video_path):\n",
        "    # Ensure the video is downloadable if possible\n",
        "    if os.path.exists(output_video_path):\n",
        "        files.download(output_video_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMZ5mtMLR2VY"
      },
      "outputs": [],
      "source": [
        "def task_pipeline():\n",
        "  set_BotSort_yaml()\n",
        "  view_BotSort_yaml()\n",
        "  cap = load_test_videos()\n",
        "  path, out = make_output_video(cap)\n",
        "  model = load_model()\n",
        "  detect_and_track_objects(model, cap, out)\n",
        "  download_output_video(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FEEs-gSmS5GT",
        "outputId": "48be993f-4ca2-4933-94fe-8376b45a6429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# default values of botsort\n",
            "tracker_type: bytetrack # tracker type, ['botsort', 'bytetrack']\n",
            "track_high_thresh: 0.6 # threshold for the first association\n",
            "track_low_thresh: 0.3 # threshold for the second association\n",
            "new_track_thresh: 0.85 # threshold for init new track if the detection does not match any tracks\n",
            "track_buffer: 100 # buffer to calculate the time when to remove tracks\n",
            "match_thresh: 0.6 # threshold for matching tracks\n",
            "fuse_score: True # Whether to fuse confidence scores with the iou distances before matching\n",
            "min_box_area: 10  # threshold for min box areas(for tracker evaluation, not used for now)\n",
            "# BoT-SORT settings\n",
            "gmc_method: sparseOptFlow # method of global motion compensation\n",
            "# ReID model related thresh (not supported yet)\n",
            "proximity_thresh: 0.6\n",
            "appearance_thresh: 0.6\n",
            "with_reid: True\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9471.7ms\n",
            "Speed: 6.8ms preprocess, 9471.7ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10253.6ms\n",
            "Speed: 8.1ms preprocess, 10253.6ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10321.1ms\n",
            "Speed: 7.5ms preprocess, 10321.1ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10354.5ms\n",
            "Speed: 5.9ms preprocess, 10354.5ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9916.8ms\n",
            "Speed: 7.5ms preprocess, 9916.8ms inference, 3.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9548.3ms\n",
            "Speed: 9.3ms preprocess, 9548.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10476.5ms\n",
            "Speed: 8.9ms preprocess, 10476.5ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10469.0ms\n",
            "Speed: 6.4ms preprocess, 10469.0ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10337.0ms\n",
            "Speed: 8.0ms preprocess, 10337.0ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9443.5ms\n",
            "Speed: 6.5ms preprocess, 9443.5ms inference, 4.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10213.3ms\n",
            "Speed: 10.3ms preprocess, 10213.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10388.7ms\n",
            "Speed: 7.5ms preprocess, 10388.7ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10320.9ms\n",
            "Speed: 6.9ms preprocess, 10320.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10325.3ms\n",
            "Speed: 6.7ms preprocess, 10325.3ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9172.5ms\n",
            "Speed: 7.2ms preprocess, 9172.5ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 1 teddy bear, 10299.2ms\n",
            "Speed: 7.7ms preprocess, 10299.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 1 teddy bear, 10366.7ms\n",
            "Speed: 7.8ms preprocess, 10366.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 1 teddy bear, 10315.1ms\n",
            "Speed: 9.1ms preprocess, 10315.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9426.8ms\n",
            "Speed: 7.2ms preprocess, 9426.8ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9943.5ms\n",
            "Speed: 9.2ms preprocess, 9943.5ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10303.3ms\n",
            "Speed: 7.3ms preprocess, 10303.3ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10298.6ms\n",
            "Speed: 6.0ms preprocess, 10298.6ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10340.3ms\n",
            "Speed: 7.3ms preprocess, 10340.3ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9110.2ms\n",
            "Speed: 7.4ms preprocess, 9110.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10234.4ms\n",
            "Speed: 7.7ms preprocess, 10234.4ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10370.5ms\n",
            "Speed: 7.5ms preprocess, 10370.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10293.8ms\n",
            "Speed: 7.4ms preprocess, 10293.8ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9456.4ms\n",
            "Speed: 6.8ms preprocess, 9456.4ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10029.8ms\n",
            "Speed: 8.6ms preprocess, 10029.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10266.9ms\n",
            "Speed: 7.9ms preprocess, 10266.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10376.0ms\n",
            "Speed: 6.8ms preprocess, 10376.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10387.9ms\n",
            "Speed: 6.1ms preprocess, 10387.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9044.9ms\n",
            "Speed: 6.7ms preprocess, 9044.9ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10269.3ms\n",
            "Speed: 6.9ms preprocess, 10269.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10345.3ms\n",
            "Speed: 7.7ms preprocess, 10345.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10311.9ms\n",
            "Speed: 7.6ms preprocess, 10311.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9455.5ms\n",
            "Speed: 6.9ms preprocess, 9455.5ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9837.8ms\n",
            "Speed: 8.1ms preprocess, 9837.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10345.2ms\n",
            "Speed: 8.0ms preprocess, 10345.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10312.8ms\n",
            "Speed: 9.1ms preprocess, 10312.8ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10379.5ms\n",
            "Speed: 7.9ms preprocess, 10379.5ms inference, 3.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9131.2ms\n",
            "Speed: 7.4ms preprocess, 9131.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10320.4ms\n",
            "Speed: 7.5ms preprocess, 10320.4ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10418.7ms\n",
            "Speed: 7.6ms preprocess, 10418.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10365.3ms\n",
            "Speed: 7.2ms preprocess, 10365.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9702.7ms\n",
            "Speed: 8.0ms preprocess, 9702.7ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9723.6ms\n",
            "Speed: 10.5ms preprocess, 9723.6ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10235.8ms\n",
            "Speed: 7.1ms preprocess, 10235.8ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10309.3ms\n",
            "Speed: 6.9ms preprocess, 10309.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10361.1ms\n",
            "Speed: 6.6ms preprocess, 10361.1ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9128.6ms\n",
            "Speed: 6.8ms preprocess, 9128.6ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10257.3ms\n",
            "Speed: 8.2ms preprocess, 10257.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10380.3ms\n",
            "Speed: 7.4ms preprocess, 10380.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10341.3ms\n",
            "Speed: 6.8ms preprocess, 10341.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9618.7ms\n",
            "Speed: 8.7ms preprocess, 9618.7ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9728.8ms\n",
            "Speed: 10.2ms preprocess, 9728.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10273.5ms\n",
            "Speed: 6.8ms preprocess, 10273.5ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10318.0ms\n",
            "Speed: 6.6ms preprocess, 10318.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10391.7ms\n",
            "Speed: 8.3ms preprocess, 10391.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9255.8ms\n",
            "Speed: 7.1ms preprocess, 9255.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10257.4ms\n",
            "Speed: 9.9ms preprocess, 10257.4ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10419.0ms\n",
            "Speed: 8.0ms preprocess, 10419.0ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10355.2ms\n",
            "Speed: 7.5ms preprocess, 10355.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9821.6ms\n",
            "Speed: 6.7ms preprocess, 9821.6ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9720.1ms\n",
            "Speed: 7.3ms preprocess, 9720.1ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10350.4ms\n",
            "Speed: 7.5ms preprocess, 10350.4ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10380.4ms\n",
            "Speed: 6.5ms preprocess, 10380.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10426.4ms\n",
            "Speed: 7.9ms preprocess, 10426.4ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9203.1ms\n",
            "Speed: 6.7ms preprocess, 9203.1ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10279.6ms\n",
            "Speed: 9.8ms preprocess, 10279.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10466.9ms\n",
            "Speed: 6.8ms preprocess, 10466.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10402.9ms\n",
            "Speed: 6.4ms preprocess, 10402.9ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10162.4ms\n",
            "Speed: 12.4ms preprocess, 10162.4ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9395.0ms\n",
            "Speed: 8.8ms preprocess, 9395.0ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10312.4ms\n",
            "Speed: 6.7ms preprocess, 10312.4ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10373.9ms\n",
            "Speed: 8.0ms preprocess, 10373.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10451.0ms\n",
            "Speed: 7.8ms preprocess, 10451.0ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9523.6ms\n",
            "Speed: 6.8ms preprocess, 9523.6ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9919.5ms\n",
            "Speed: 9.5ms preprocess, 9919.5ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10344.9ms\n",
            "Speed: 8.0ms preprocess, 10344.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10363.3ms\n",
            "Speed: 8.3ms preprocess, 10363.3ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10296.5ms\n",
            "Speed: 6.9ms preprocess, 10296.5ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9103.7ms\n",
            "Speed: 7.3ms preprocess, 9103.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10276.1ms\n",
            "Speed: 7.3ms preprocess, 10276.1ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10348.8ms\n",
            "Speed: 8.0ms preprocess, 10348.8ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10446.5ms\n",
            "Speed: 6.6ms preprocess, 10446.5ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9642.7ms\n",
            "Speed: 6.8ms preprocess, 9642.7ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9788.6ms\n",
            "Speed: 7.7ms preprocess, 9788.6ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10385.9ms\n",
            "Speed: 7.9ms preprocess, 10385.9ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10401.9ms\n",
            "Speed: 8.4ms preprocess, 10401.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10389.9ms\n",
            "Speed: 7.0ms preprocess, 10389.9ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9215.7ms\n",
            "Speed: 7.5ms preprocess, 9215.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10328.8ms\n",
            "Speed: 7.7ms preprocess, 10328.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10333.2ms\n",
            "Speed: 7.9ms preprocess, 10333.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10275.8ms\n",
            "Speed: 7.7ms preprocess, 10275.8ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9783.0ms\n",
            "Speed: 8.9ms preprocess, 9783.0ms inference, 3.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9771.9ms\n",
            "Speed: 7.3ms preprocess, 9771.9ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10370.4ms\n",
            "Speed: 8.1ms preprocess, 10370.4ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10374.2ms\n",
            "Speed: 6.4ms preprocess, 10374.2ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10415.1ms\n",
            "Speed: 8.1ms preprocess, 10415.1ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9165.3ms\n",
            "Speed: 8.3ms preprocess, 9165.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10346.9ms\n",
            "Speed: 6.9ms preprocess, 10346.9ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10416.5ms\n",
            "Speed: 7.8ms preprocess, 10416.5ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10339.6ms\n",
            "Speed: 7.9ms preprocess, 10339.6ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9852.4ms\n",
            "Speed: 6.2ms preprocess, 9852.4ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9659.2ms\n",
            "Speed: 7.7ms preprocess, 9659.2ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10407.6ms\n",
            "Speed: 8.1ms preprocess, 10407.6ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10355.9ms\n",
            "Speed: 7.5ms preprocess, 10355.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10375.3ms\n",
            "Speed: 6.4ms preprocess, 10375.3ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9230.3ms\n",
            "Speed: 8.5ms preprocess, 9230.3ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10292.2ms\n",
            "Speed: 8.5ms preprocess, 10292.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10504.4ms\n",
            "Speed: 8.4ms preprocess, 10504.4ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10287.8ms\n",
            "Speed: 7.7ms preprocess, 10287.8ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10310.8ms\n",
            "Speed: 8.5ms preprocess, 10310.8ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9224.5ms\n",
            "Speed: 7.2ms preprocess, 9224.5ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10189.2ms\n",
            "Speed: 7.5ms preprocess, 10189.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10285.1ms\n",
            "Speed: 6.7ms preprocess, 10285.1ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10318.7ms\n",
            "Speed: 7.0ms preprocess, 10318.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9491.9ms\n",
            "Speed: 8.5ms preprocess, 9491.9ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9924.3ms\n",
            "Speed: 7.7ms preprocess, 9924.3ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10403.3ms\n",
            "Speed: 7.9ms preprocess, 10403.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10373.3ms\n",
            "Speed: 6.1ms preprocess, 10373.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10338.7ms\n",
            "Speed: 8.6ms preprocess, 10338.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9141.7ms\n",
            "Speed: 7.1ms preprocess, 9141.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10232.4ms\n",
            "Speed: 7.3ms preprocess, 10232.4ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10334.4ms\n",
            "Speed: 7.4ms preprocess, 10334.4ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10309.8ms\n",
            "Speed: 7.9ms preprocess, 10309.8ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9546.3ms\n",
            "Speed: 7.3ms preprocess, 9546.3ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9718.3ms\n",
            "Speed: 7.2ms preprocess, 9718.3ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10388.0ms\n",
            "Speed: 7.3ms preprocess, 10388.0ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10247.5ms\n",
            "Speed: 6.7ms preprocess, 10247.5ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10328.9ms\n",
            "Speed: 8.4ms preprocess, 10328.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9151.7ms\n",
            "Speed: 8.0ms preprocess, 9151.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10206.3ms\n",
            "Speed: 7.2ms preprocess, 10206.3ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10348.8ms\n",
            "Speed: 8.2ms preprocess, 10348.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10342.7ms\n",
            "Speed: 6.4ms preprocess, 10342.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9706.0ms\n",
            "Speed: 6.6ms preprocess, 9706.0ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9710.1ms\n",
            "Speed: 8.3ms preprocess, 9710.1ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10371.5ms\n",
            "Speed: 7.3ms preprocess, 10371.5ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10307.3ms\n",
            "Speed: 7.4ms preprocess, 10307.3ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10288.2ms\n",
            "Speed: 7.3ms preprocess, 10288.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9162.5ms\n",
            "Speed: 7.7ms preprocess, 9162.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10192.7ms\n",
            "Speed: 6.8ms preprocess, 10192.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10318.9ms\n",
            "Speed: 6.5ms preprocess, 10318.9ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10327.5ms\n",
            "Speed: 7.7ms preprocess, 10327.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9761.7ms\n",
            "Speed: 6.5ms preprocess, 9761.7ms inference, 6.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 9604.6ms\n",
            "Speed: 8.4ms preprocess, 9604.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10286.3ms\n",
            "Speed: 7.3ms preprocess, 10286.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10319.0ms\n",
            "Speed: 6.8ms preprocess, 10319.0ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 2 dogs, 10283.0ms\n",
            "Speed: 6.6ms preprocess, 10283.0ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9131.3ms\n",
            "Speed: 8.0ms preprocess, 9131.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10175.1ms\n",
            "Speed: 6.9ms preprocess, 10175.1ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10251.1ms\n",
            "Speed: 7.5ms preprocess, 10251.1ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10273.9ms\n",
            "Speed: 5.7ms preprocess, 10273.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9701.4ms\n",
            "Speed: 7.1ms preprocess, 9701.4ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 4 persons, 9705.7ms\n",
            "Speed: 8.2ms preprocess, 9705.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10297.6ms\n",
            "Speed: 7.2ms preprocess, 10297.6ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 4 persons, 10304.8ms\n",
            "Speed: 7.6ms preprocess, 10304.8ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 cake, 10308.8ms\n",
            "Speed: 7.0ms preprocess, 10308.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 cake, 9210.5ms\n",
            "Speed: 8.3ms preprocess, 9210.5ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 10308.9ms\n",
            "Speed: 6.8ms preprocess, 10308.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 10228.9ms\n",
            "Speed: 7.6ms preprocess, 10228.9ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 10287.0ms\n",
            "Speed: 7.9ms preprocess, 10287.0ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 9725.2ms\n",
            "Speed: 6.7ms preprocess, 9725.2ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 9639.2ms\n",
            "Speed: 7.8ms preprocess, 9639.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 10234.2ms\n",
            "Speed: 7.4ms preprocess, 10234.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 10283.1ms\n",
            "Speed: 5.8ms preprocess, 10283.1ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 10455.3ms\n",
            "Speed: 7.4ms preprocess, 10455.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 9162.7ms\n",
            "Speed: 7.9ms preprocess, 9162.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 10283.9ms\n",
            "Speed: 6.8ms preprocess, 10283.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10313.8ms\n",
            "Speed: 8.6ms preprocess, 10313.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10361.6ms\n",
            "Speed: 8.1ms preprocess, 10361.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10004.7ms\n",
            "Speed: 7.0ms preprocess, 10004.7ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9456.2ms\n",
            "Speed: 7.4ms preprocess, 9456.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10321.5ms\n",
            "Speed: 6.9ms preprocess, 10321.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10327.0ms\n",
            "Speed: 6.7ms preprocess, 10327.0ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10244.7ms\n",
            "Speed: 7.8ms preprocess, 10244.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9089.7ms\n",
            "Speed: 7.9ms preprocess, 9089.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10121.6ms\n",
            "Speed: 6.9ms preprocess, 10121.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10310.1ms\n",
            "Speed: 6.6ms preprocess, 10310.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10300.7ms\n",
            "Speed: 7.9ms preprocess, 10300.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9986.3ms\n",
            "Speed: 7.0ms preprocess, 9986.3ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9484.7ms\n",
            "Speed: 7.6ms preprocess, 9484.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10328.2ms\n",
            "Speed: 8.0ms preprocess, 10328.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10339.3ms\n",
            "Speed: 5.9ms preprocess, 10339.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10275.2ms\n",
            "Speed: 7.9ms preprocess, 10275.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9277.9ms\n",
            "Speed: 8.6ms preprocess, 9277.9ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10090.2ms\n",
            "Speed: 9.5ms preprocess, 10090.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10213.6ms\n",
            "Speed: 6.9ms preprocess, 10213.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10308.9ms\n",
            "Speed: 8.5ms preprocess, 10308.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9913.5ms\n",
            "Speed: 7.2ms preprocess, 9913.5ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9376.2ms\n",
            "Speed: 7.3ms preprocess, 9376.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10268.1ms\n",
            "Speed: 6.8ms preprocess, 10268.1ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10341.4ms\n",
            "Speed: 8.5ms preprocess, 10341.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10273.2ms\n",
            "Speed: 7.8ms preprocess, 10273.2ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9204.3ms\n",
            "Speed: 8.3ms preprocess, 9204.3ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10019.9ms\n",
            "Speed: 7.3ms preprocess, 10019.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10342.6ms\n",
            "Speed: 7.6ms preprocess, 10342.6ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10274.4ms\n",
            "Speed: 11.6ms preprocess, 10274.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10185.5ms\n",
            "Speed: 6.8ms preprocess, 10185.5ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9221.2ms\n",
            "Speed: 7.1ms preprocess, 9221.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10283.4ms\n",
            "Speed: 8.0ms preprocess, 10283.4ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10357.2ms\n",
            "Speed: 7.0ms preprocess, 10357.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10208.3ms\n",
            "Speed: 7.6ms preprocess, 10208.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9322.9ms\n",
            "Speed: 6.8ms preprocess, 9322.9ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9973.8ms\n",
            "Speed: 9.4ms preprocess, 9973.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10340.0ms\n",
            "Speed: 7.3ms preprocess, 10340.0ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10276.3ms\n",
            "Speed: 8.3ms preprocess, 10276.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10320.6ms\n",
            "Speed: 5.8ms preprocess, 10320.6ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9119.3ms\n",
            "Speed: 7.3ms preprocess, 9119.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10314.8ms\n",
            "Speed: 8.1ms preprocess, 10314.8ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 10266.7ms\n",
            "Speed: 6.7ms preprocess, 10266.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10288.8ms\n",
            "Speed: 7.7ms preprocess, 10288.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9405.9ms\n",
            "Speed: 8.1ms preprocess, 9405.9ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 9868.2ms\n",
            "Speed: 7.6ms preprocess, 9868.2ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10433.2ms\n",
            "Speed: 8.5ms preprocess, 10433.2ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n",
            "\n",
            "0: 736x1280 3 persons, 1 dog, 10305.4ms\n",
            "Speed: 7.9ms preprocess, 10305.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49782f85-76be-48a1-9421-3c956351db8e\", \"output_video.mp4\", 6444391)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "task_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change and adjust Kalman filter parameters"
      ],
      "metadata": {
        "id": "QgGltg_5-W1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the find command to search for kalman_filter.py file in the entire file system\n",
        "!find / -name \"kalman_filter.py\" 2>/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSdTJBli7NHi",
        "outputId": "4fe756ee-63ad-4533-933f-9711a8f5143c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ultralytics/trackers/utils/kalman_filter.py\n",
            "/usr/local/lib/python3.10/dist-packages/filterpy/kalman/kalman_filter.py\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/tsa/statespace/kalman_filter.py\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}